{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrebw/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from src.dataset import SPFastaDatasetBinary, SPFastaDatasetBinaryWithTokenizedCategory\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20290 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20290/20290 [00:00<00:00, 283887.68it/s]\n",
      "100%|██████████| 20290/20290 [00:00<00:00, 542368.05it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = SPFastaDatasetBinaryWithTokenizedCategory(\"data/train.fasta\")\n",
    "dataset_train = Dataset.from_pandas(ds.data).with_format(\"torch\", device=device)\n",
    "del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20290/20290 [00:01<00:00, 12991.73 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sequence', 'label', 'uniprot_ac', 'kingdom', 'type', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 20290\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize:\n",
    "dataset_train = dataset_train.map(lambda x: tokenizer(x['sequence'], return_tensors=\"pt\", padding=True), batched=True)\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "class ProtBertSequenceClassification:\n",
    "    def __init__(self, device: str=device) -> None:\n",
    "        self.device = device\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"Rostlab/prot_bert\", num_labels=2).to(device)\n",
    "        self.model.train()\n",
    "        self.model.label2id = {\n",
    "            'NO_SP': 0,\n",
    "            'SP': 1\n",
    "        }\n",
    "        self.model.id2label= {\n",
    "            0: 'NO_SP',\n",
    "            1: 'SP'\n",
    "        }\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert\", device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model.forward(x).logits\n",
    "        return nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        pred = self.forward(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sample = dataset_train[0]\n",
    "model = ProtBertSequenceClassification()\n",
    "# model.forward(input_ids=sample['input_ids'].reshape(1, -1), attention_mask=sample['attention_mask'].reshape(1, -1)).logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
