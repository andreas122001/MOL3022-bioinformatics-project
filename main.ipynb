{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from src.dataset import SPFastaDatasetBinary, SPFastaDatasetBinaryWithTokenizedCategory\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = SPFastaDatasetBinaryWithTokenizedCategory(\"data/train.fasta\")\n",
    "# dataset_train = Dataset.from_pandas(ds.data).with_format(\"torch\", device=device)\n",
    "# ds = SPFastaDatasetBinaryWithTokenizedCategory(\"data/test.fasta\")\n",
    "# dataset_test = Dataset.from_pandas(ds.data).with_format(\"torch\", device=device)\n",
    "# del ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20290/20290 [00:00<00:00, 183476.44it/s]\n",
      "100%|██████████| 20290/20290 [00:00<00:00, 534029.63it/s]\n",
      "100%|██████████| 8811/8811 [00:00<00:00, 259114.96it/s]\n",
      "100%|██████████| 8811/8811 [00:00<00:00, 734434.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data_with_size_uniform(path, size=1000):\n",
    "    ds = SPFastaDatasetBinaryWithTokenizedCategory(path)\n",
    "    neg_labels = ds.data.loc[ds.data['labels'] == 0][:size//2]\n",
    "    pos_labels = ds.data.loc[ds.data['labels'] == 1][:size//2]\n",
    "    combi = pd.concat((neg_labels, pos_labels))\n",
    "    return Dataset.from_pandas(combi).with_format(\"torch\", device=device)\n",
    "\n",
    "dataset_train = load_data_with_size_uniform(\"data/train.fasta\", 100000)\n",
    "dataset_test  = load_data_with_size_uniform(\"data/test.fasta\", 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3f644966ca4a8e9203ee622673c6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/20290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ea94e0799a47508c93f954db786068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/8811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "dataset_train = dataset_train.cast_column('labels', ClassLabel(num_classes = 2, names=[\"NO_SP\", \"SP\"]))\n",
    "dataset_test = dataset_test.cast_column('labels', ClassLabel(num_classes = 2, names=[\"NO_SP\", \"SP\"]))\n",
    "dataset_train[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1db7591bf8a4ecfb0b3a8305a9871af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e597f2450e64ff398ba62ef348db621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'labels', 'uniprot_ac', 'kingdom', 'type', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 20290\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'labels', 'uniprot_ac', 'kingdom', 'type', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 8811\n",
       " }))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert\", device=\"cpu\")\n",
    "dataset_train = dataset_train.map(lambda x: tokenizer(x['text'], return_tensors=\"pt\", padding='max_length', max_length=81, truncation=True), batched=True)\n",
    "dataset_test = dataset_test.map(lambda x: tokenizer(x['text'], return_tensors=\"pt\", padding='max_length', max_length=81, truncation=True), batched=True)\n",
    "dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "pre = evaluate.load(\"precision\")\n",
    "rec = evaluate.load(\"recall\")\n",
    "f1m = evaluate.load(\"f1\")\n",
    "\n",
    "metrics = [acc, pre, rec, f1m]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, y = eval_pred\n",
    "    x = logits.argmax(-1)\n",
    "    return {k: v for metric in [m.compute(predictions=x, references=y) for m in metrics] for k, v in metric.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "class ProtBertSequenceClassification(nn.Module):\n",
    "    def __init__(self, device: str=device) -> None:\n",
    "        super(ProtBertSequenceClassification, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            #\"Rostlab/prot_bert\",\n",
    "            \"microsoft/MiniLM-L12-H384-uncased\",\n",
    "            num_labels=2,\n",
    "            label2id = {\n",
    "                'NO_SP': 0,\n",
    "                'SP': 1\n",
    "            },\n",
    "            id2label= {\n",
    "                0: 'NO_SP',\n",
    "                1: 'SP'\n",
    "            }).to(device)\n",
    "\n",
    "        self.loss_fn = nn.functional.binary_cross_entropy\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, token_type_ids=None):\n",
    "        outputs = self.model.forward(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs\n",
    "    \n",
    "    def loss(self, x, weights=None):\n",
    "        logits = self.forward(x).logits[:,1]\n",
    "        pred = logits.softmax(-1)\n",
    "        label = x['labels']\n",
    "        return self.loss_fn(pred, label.float(), weight=weights)\n",
    "\n",
    "model = ProtBertSequenceClassification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FocalLoss, compute class weights and create a custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weights, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = weights\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6493, 2.1747], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=dataset_train['labels'].cpu().numpy())\n",
    "class_weights = torch.tensor(class_weights).to(device).float()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        labels = inputs.get('labels')\n",
    "\n",
    "        loss_fn = FocalLoss(weights=class_weights)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# batch_size = 8\n",
    "epochs = 50\n",
    "logging_steps=1000\n",
    "eval_steps=10000\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./model',\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=epochs,\n",
    "    learning_rate=2e-5,\n",
    "    logging_first_step=True,\n",
    "    weight_decay=0.0001,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=logging_steps,\n",
    "    eval_steps=eval_steps,\n",
    "    fp16=True,\n",
    "    optim='adamw_torch',\n",
    "    remove_unused_columns=True,\n",
    "    auto_find_batch_size=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748474b7bb614caeae90170887a40aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1488, 'learning_rate': 1.9999842333464724e-05, 'epoch': 0.0}\n",
      "{'loss': 0.1737, 'learning_rate': 1.9842333464722114e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1713, 'learning_rate': 1.968498226251478e-05, 'epoch': 0.79}\n",
      "{'loss': 0.1741, 'learning_rate': 1.9527315727236894e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1357, 'learning_rate': 1.9369806858494287e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0985, 'learning_rate': 1.92121403232164e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0746, 'learning_rate': 1.9054473787938513e-05, 'epoch': 2.36}\n",
      "{'loss': 0.077, 'learning_rate': 1.8897437918801735e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0747, 'learning_rate': 1.8739771383523847e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0607, 'learning_rate': 1.858210484824596e-05, 'epoch': 3.55}\n",
      "{'loss': 0.0648, 'learning_rate': 1.8424438312968072e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18d90265d5d445aa40f2719028c73b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.047781217843294144, 'eval_accuracy': 0.971966859607309, 'eval_precision': 0.9169491525423729, 'eval_recall': 0.8789601949634444, 'eval_f1': 0.8975528826213189, 'eval_runtime': 30.9282, 'eval_samples_per_second': 284.886, 'eval_steps_per_second': 35.631, 'epoch': 3.94}\n",
      "{'loss': 0.0604, 'learning_rate': 1.8266771777690185e-05, 'epoch': 4.34}\n",
      "{'loss': 0.0587, 'learning_rate': 1.8109105242412298e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0635, 'learning_rate': 1.795159637366969e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0558, 'learning_rate': 1.779408750492708e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0525, 'learning_rate': 1.7636420969649194e-05, 'epoch': 5.91}\n",
      "{'loss': 0.05, 'learning_rate': 1.7478754434371306e-05, 'epoch': 6.31}\n",
      "{'loss': 0.0513, 'learning_rate': 1.7321245565628696e-05, 'epoch': 6.7}\n",
      "{'loss': 0.0423, 'learning_rate': 1.716357903035081e-05, 'epoch': 7.09}\n",
      "{'loss': 0.0417, 'learning_rate': 1.70060701616082e-05, 'epoch': 7.49}\n",
      "{'loss': 0.0432, 'learning_rate': 1.684840362633031e-05, 'epoch': 7.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42be3fa29b49484bb73c0f197069aee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03126443922519684, 'eval_accuracy': 0.9800249687890137, 'eval_precision': 0.9189833200953137, 'eval_recall': 0.9398862713241267, 'eval_f1': 0.9293172690763052, 'eval_runtime': 30.5459, 'eval_samples_per_second': 288.451, 'eval_steps_per_second': 36.077, 'epoch': 7.88}\n",
      "{'loss': 0.0378, 'learning_rate': 1.6690737091052424e-05, 'epoch': 8.28}\n",
      "{'loss': 0.041, 'learning_rate': 1.6533070555774536e-05, 'epoch': 8.67}\n",
      "{'loss': 0.0403, 'learning_rate': 1.637540402049665e-05, 'epoch': 9.07}\n",
      "{'loss': 0.0338, 'learning_rate': 1.621805281828932e-05, 'epoch': 9.46}\n",
      "{'loss': 0.0352, 'learning_rate': 1.6060386283011432e-05, 'epoch': 9.85}\n",
      "{'loss': 0.0356, 'learning_rate': 1.5902877414268822e-05, 'epoch': 10.25}\n",
      "{'loss': 0.0343, 'learning_rate': 1.5745210878990935e-05, 'epoch': 10.64}\n",
      "{'loss': 0.039, 'learning_rate': 1.5587702010248328e-05, 'epoch': 11.04}\n",
      "{'loss': 0.0336, 'learning_rate': 1.543003547497044e-05, 'epoch': 11.43}\n",
      "{'loss': 0.0294, 'learning_rate': 1.5272368939692553e-05, 'epoch': 11.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408cf7a47960413697f4dbf8fa0a6e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.023840567097067833, 'eval_accuracy': 0.9878560889796845, 'eval_precision': 0.9599018003273322, 'eval_recall': 0.9528838342810723, 'eval_f1': 0.9563799429270281, 'eval_runtime': 29.3298, 'eval_samples_per_second': 300.411, 'eval_steps_per_second': 37.573, 'epoch': 11.82}\n",
      "{'loss': 0.0362, 'learning_rate': 1.5114702404414664e-05, 'epoch': 12.22}\n",
      "{'loss': 0.0352, 'learning_rate': 1.4957035869136779e-05, 'epoch': 12.61}\n",
      "{'loss': 0.0297, 'learning_rate': 1.4799369333858891e-05, 'epoch': 13.01}\n",
      "{'loss': 0.0316, 'learning_rate': 1.464186046511628e-05, 'epoch': 13.4}\n",
      "{'loss': 0.0312, 'learning_rate': 1.4484193929838392e-05, 'epoch': 13.8}\n",
      "{'loss': 0.0315, 'learning_rate': 1.4326527394560506e-05, 'epoch': 14.19}\n",
      "{'loss': 0.0275, 'learning_rate': 1.4168860859282619e-05, 'epoch': 14.58}\n",
      "{'loss': 0.0431, 'learning_rate': 1.401135199054001e-05, 'epoch': 14.98}\n",
      "{'loss': 0.034, 'learning_rate': 1.3853843121797399e-05, 'epoch': 15.37}\n",
      "{'loss': 0.0275, 'learning_rate': 1.3696176586519511e-05, 'epoch': 15.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6277b034017a459fadb0fd451b39b4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022756921127438545, 'eval_accuracy': 0.9868346385200317, 'eval_precision': 0.9657477025898078, 'eval_recall': 0.9390739236393176, 'eval_f1': 0.9522240527182867, 'eval_runtime': 29.4347, 'eval_samples_per_second': 299.34, 'eval_steps_per_second': 37.439, 'epoch': 15.77}\n",
      "{'loss': 0.0285, 'learning_rate': 1.3538510051241624e-05, 'epoch': 16.16}\n",
      "{'loss': 0.0286, 'learning_rate': 1.3381001182499016e-05, 'epoch': 16.55}\n",
      "{'loss': 0.0279, 'learning_rate': 1.3223334647221128e-05, 'epoch': 16.95}\n",
      "{'loss': 0.0254, 'learning_rate': 1.306566811194324e-05, 'epoch': 17.34}\n",
      "{'loss': 0.0239, 'learning_rate': 1.2908001576665355e-05, 'epoch': 17.74}\n",
      "{'loss': 0.0269, 'learning_rate': 1.2750335041387468e-05, 'epoch': 18.13}\n",
      "{'loss': 0.0268, 'learning_rate': 1.259266850610958e-05, 'epoch': 18.53}\n",
      "{'loss': 0.0242, 'learning_rate': 1.2435001970831693e-05, 'epoch': 18.92}\n",
      "{'loss': 0.0268, 'learning_rate': 1.2277493102089081e-05, 'epoch': 19.31}\n",
      "{'loss': 0.0268, 'learning_rate': 1.2119984233346473e-05, 'epoch': 19.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502b991238d947ab83e728ba16c2ff71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.017343735322356224, 'eval_accuracy': 0.9872886165020996, 'eval_precision': 0.9612530915086562, 'eval_recall': 0.9471974004874086, 'eval_f1': 0.9541734860883797, 'eval_runtime': 29.9772, 'eval_samples_per_second': 293.923, 'eval_steps_per_second': 36.761, 'epoch': 19.71}\n",
      "{'loss': 0.0238, 'learning_rate': 1.1962317698068587e-05, 'epoch': 20.1}\n",
      "{'loss': 0.0279, 'learning_rate': 1.1804808829325975e-05, 'epoch': 20.5}\n",
      "{'loss': 0.0251, 'learning_rate': 1.1647142294048088e-05, 'epoch': 20.89}\n",
      "{'loss': 0.0258, 'learning_rate': 1.148963342530548e-05, 'epoch': 21.28}\n",
      "{'loss': 0.0233, 'learning_rate': 1.1331966890027592e-05, 'epoch': 21.68}\n",
      "{'loss': 0.0281, 'learning_rate': 1.1174458021284984e-05, 'epoch': 22.07}\n",
      "{'loss': 0.0255, 'learning_rate': 1.1016949152542374e-05, 'epoch': 22.47}\n",
      "{'loss': 0.0251, 'learning_rate': 1.0859282617264486e-05, 'epoch': 22.86}\n",
      "{'loss': 0.0252, 'learning_rate': 1.0701616081986599e-05, 'epoch': 23.26}\n",
      "{'loss': 0.0192, 'learning_rate': 1.0543949546708712e-05, 'epoch': 23.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1787d6ac7b8a46eab28343152a3939ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.01524350605905056, 'eval_accuracy': 0.9854727045738282, 'eval_precision': 0.9168556311413454, 'eval_recall': 0.9853777416734363, 'eval_f1': 0.9498825371965545, 'eval_runtime': 29.585, 'eval_samples_per_second': 297.82, 'eval_steps_per_second': 37.249, 'epoch': 23.65}\n",
      "{'loss': 0.0223, 'learning_rate': 1.0386440677966103e-05, 'epoch': 24.04}\n",
      "{'loss': 0.0221, 'learning_rate': 1.0228774142688216e-05, 'epoch': 24.44}\n",
      "{'loss': 0.0232, 'learning_rate': 1.0071107607410328e-05, 'epoch': 24.83}\n",
      "{'loss': 0.0215, 'learning_rate': 9.913441072132441e-06, 'epoch': 25.23}\n",
      "{'loss': 0.0221, 'learning_rate': 9.755774536854554e-06, 'epoch': 25.62}\n",
      "{'loss': 0.0216, 'learning_rate': 9.598265668111943e-06, 'epoch': 26.01}\n",
      "{'loss': 0.0215, 'learning_rate': 9.440599132834056e-06, 'epoch': 26.41}\n",
      "{'loss': 0.02, 'learning_rate': 9.282932597556169e-06, 'epoch': 26.8}\n",
      "{'loss': 0.0227, 'learning_rate': 9.12542372881356e-06, 'epoch': 27.2}\n",
      "{'loss': 0.018, 'learning_rate': 8.967757193535673e-06, 'epoch': 27.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d945217ad9564cea96692d783bf78dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.011301785707473755, 'eval_accuracy': 0.9919418908182953, 'eval_precision': 0.9566929133858267, 'eval_recall': 0.9870024370430545, 'eval_f1': 0.9716113554578168, 'eval_runtime': 29.5941, 'eval_samples_per_second': 297.728, 'eval_steps_per_second': 37.237, 'epoch': 27.59}\n",
      "{'loss': 0.0211, 'learning_rate': 8.810248324793063e-06, 'epoch': 27.99}\n",
      "{'loss': 0.0199, 'learning_rate': 8.652581789515177e-06, 'epoch': 28.38}\n",
      "{'loss': 0.0197, 'learning_rate': 8.49491525423729e-06, 'epoch': 28.77}\n",
      "{'loss': 0.0216, 'learning_rate': 8.337248718959402e-06, 'epoch': 29.17}\n",
      "{'loss': 0.0177, 'learning_rate': 8.17989751675207e-06, 'epoch': 29.56}\n",
      "{'loss': 0.0193, 'learning_rate': 8.022230981474182e-06, 'epoch': 29.96}\n",
      "{'loss': 0.0167, 'learning_rate': 7.864564446196295e-06, 'epoch': 30.35}\n",
      "{'loss': 0.0181, 'learning_rate': 7.706897910918409e-06, 'epoch': 30.74}\n",
      "{'loss': 0.0194, 'learning_rate': 7.549231375640521e-06, 'epoch': 31.14}\n",
      "{'loss': 0.0155, 'learning_rate': 7.3915648403626335e-06, 'epoch': 31.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43debc239bf4f34bd0d8824c7990159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.012764379382133484, 'eval_accuracy': 0.9923958688003632, 'eval_precision': 0.9656, 'eval_recall': 0.9805036555645816, 'eval_f1': 0.9729947601773479, 'eval_runtime': 29.6436, 'eval_samples_per_second': 297.231, 'eval_steps_per_second': 37.175, 'epoch': 31.53}\n",
      "{'loss': 0.018, 'learning_rate': 7.233898305084747e-06, 'epoch': 31.93}\n",
      "{'loss': 0.0184, 'learning_rate': 7.076389436342137e-06, 'epoch': 32.32}\n",
      "{'loss': 0.0169, 'learning_rate': 6.9187229010642495e-06, 'epoch': 32.72}\n",
      "{'loss': 0.0172, 'learning_rate': 6.76121403232164e-06, 'epoch': 33.11}\n",
      "{'loss': 0.0191, 'learning_rate': 6.603547497043753e-06, 'epoch': 33.5}\n",
      "{'loss': 0.0136, 'learning_rate': 6.446038628301144e-06, 'epoch': 33.9}\n",
      "{'loss': 0.0173, 'learning_rate': 6.288372093023256e-06, 'epoch': 34.29}\n",
      "{'loss': 0.0161, 'learning_rate': 6.130705557745369e-06, 'epoch': 34.69}\n",
      "{'loss': 0.0143, 'learning_rate': 5.97319668900276e-06, 'epoch': 35.08}\n",
      "{'loss': 0.0142, 'learning_rate': 5.815530153724872e-06, 'epoch': 35.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c19d1509fc447f9bbde2bb07239ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00998597126454115, 'eval_accuracy': 0.9943252752241516, 'eval_precision': 0.9720223820943246, 'eval_recall': 0.9878147847278635, 'eval_f1': 0.9798549556809025, 'eval_runtime': 29.6518, 'eval_samples_per_second': 297.149, 'eval_steps_per_second': 37.165, 'epoch': 35.47}\n",
      "{'loss': 0.0157, 'learning_rate': 5.657863618446985e-06, 'epoch': 35.87}\n",
      "{'loss': 0.0164, 'learning_rate': 5.500354749704376e-06, 'epoch': 36.26}\n",
      "{'loss': 0.0159, 'learning_rate': 5.342688214426488e-06, 'epoch': 36.66}\n",
      "{'loss': 0.0134, 'learning_rate': 5.18517934568388e-06, 'epoch': 37.05}\n",
      "{'loss': 0.0148, 'learning_rate': 5.0275128104059924e-06, 'epoch': 37.45}\n",
      "{'loss': 0.0119, 'learning_rate': 4.870003941663382e-06, 'epoch': 37.84}\n",
      "{'loss': 0.0116, 'learning_rate': 4.712337406385495e-06, 'epoch': 38.23}\n",
      "{'loss': 0.0128, 'learning_rate': 4.554670871107608e-06, 'epoch': 38.63}\n",
      "{'loss': 0.016, 'learning_rate': 4.397162002364998e-06, 'epoch': 39.02}\n",
      "{'loss': 0.016, 'learning_rate': 4.239495467087111e-06, 'epoch': 39.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bebd4c31454137ae7992e0d5630854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.009744029492139816, 'eval_accuracy': 0.9950062421972534, 'eval_precision': 0.9759422614274258, 'eval_recall': 0.9886271324126726, 'eval_f1': 0.9822437449556094, 'eval_runtime': 29.5778, 'eval_samples_per_second': 297.892, 'eval_steps_per_second': 37.258, 'epoch': 39.42}\n",
      "{'loss': 0.0126, 'learning_rate': 4.081986598344502e-06, 'epoch': 39.81}\n",
      "{'loss': 0.015, 'learning_rate': 3.924320063066614e-06, 'epoch': 40.2}\n",
      "{'loss': 0.0116, 'learning_rate': 3.7666535277887274e-06, 'epoch': 40.6}\n",
      "{'loss': 0.013, 'learning_rate': 3.60898699251084e-06, 'epoch': 40.99}\n",
      "{'loss': 0.0119, 'learning_rate': 3.4514781237682304e-06, 'epoch': 41.39}\n",
      "{'loss': 0.0117, 'learning_rate': 3.2938115884903434e-06, 'epoch': 41.78}\n",
      "{'loss': 0.0107, 'learning_rate': 3.136145053212456e-06, 'epoch': 42.18}\n",
      "{'loss': 0.0103, 'learning_rate': 2.9786361844698463e-06, 'epoch': 42.57}\n",
      "{'loss': 0.0137, 'learning_rate': 2.8209696491919594e-06, 'epoch': 42.96}\n",
      "{'loss': 0.0122, 'learning_rate': 2.663303113914072e-06, 'epoch': 43.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1e4612aaac4a2d9b73a19ca45848e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.010858706198632717, 'eval_accuracy': 0.9962546816479401, 'eval_precision': 0.9885807504078303, 'eval_recall': 0.9845653939886271, 'eval_f1': 0.9865689865689866, 'eval_runtime': 29.5587, 'eval_samples_per_second': 298.085, 'eval_steps_per_second': 37.282, 'epoch': 43.36}\n",
      "{'loss': 0.0104, 'learning_rate': 2.5056365786361845e-06, 'epoch': 43.75}\n",
      "{'loss': 0.013, 'learning_rate': 2.3481277098935753e-06, 'epoch': 44.15}\n",
      "{'loss': 0.0095, 'learning_rate': 2.190461174615688e-06, 'epoch': 44.54}\n",
      "{'loss': 0.0114, 'learning_rate': 2.0329523058730783e-06, 'epoch': 44.93}\n",
      "{'loss': 0.0116, 'learning_rate': 1.8752857705951913e-06, 'epoch': 45.33}\n",
      "{'loss': 0.0084, 'learning_rate': 1.7176192353173041e-06, 'epoch': 45.72}\n",
      "{'loss': 0.0134, 'learning_rate': 1.559952700039417e-06, 'epoch': 46.12}\n",
      "{'loss': 0.0116, 'learning_rate': 1.4024438312968075e-06, 'epoch': 46.51}\n",
      "{'loss': 0.0116, 'learning_rate': 1.2449349625541981e-06, 'epoch': 46.91}\n",
      "{'loss': 0.0087, 'learning_rate': 1.0872684272763107e-06, 'epoch': 47.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ffeed3e91b4cc0b628ed5245875ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.010331220924854279, 'eval_accuracy': 0.9962546816479401, 'eval_precision': 0.987785016286645, 'eval_recall': 0.9853777416734363, 'eval_f1': 0.9865799105327369, 'eval_runtime': 29.6133, 'eval_samples_per_second': 297.536, 'eval_steps_per_second': 37.213, 'epoch': 47.3}\n",
      "{'loss': 0.0127, 'learning_rate': 9.296018919984234e-07, 'epoch': 47.69}\n",
      "{'loss': 0.0113, 'learning_rate': 7.719353567205361e-07, 'epoch': 48.09}\n",
      "{'loss': 0.0103, 'learning_rate': 6.144264879779267e-07, 'epoch': 48.48}\n",
      "{'loss': 0.0078, 'learning_rate': 4.5675995270003944e-07, 'epoch': 48.88}\n",
      "{'loss': 0.0095, 'learning_rate': 2.992510839574301e-07, 'epoch': 49.27}\n",
      "{'loss': 0.0097, 'learning_rate': 1.4158454867954278e-07, 'epoch': 49.66}\n",
      "{'train_runtime': 17828.2412, 'train_samples_per_second': 56.904, 'train_steps_per_second': 7.115, 'train_loss': 0.03027781485782912, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126850, training_loss=0.03027781485782912, metrics={'train_runtime': 17828.2412, 'train_samples_per_second': 56.904, 'train_steps_per_second': 7.115, 'train_loss': 0.03027781485782912, 'epoch': 50.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = WeightedLossTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = dataset_test.select_columns(['input_ids', 'attention_mask', 'labels'])\n",
    "sample = samples[torch.randint(len(samples), (1,))]\n",
    "with torch.no_grad():\n",
    "    pred = model(**sample).logits.argmax(-1)\n",
    "pred-sample['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd3f532f7cd4984bbe83ad27a00d1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "for batch in tqdm(torch.utils.data.DataLoader(samples, batch_size=8)):\n",
    "    pred = model(**batch).logits.argmax(-1)\n",
    "    for p, l in zip(pred, batch['labels']):\n",
    "        res.append((p.item(), l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred  label\n",
       "0     0        7558\n",
       "1     1        1205\n",
       "0     1          26\n",
       "1     0          22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res, columns=['pred', 'label']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# TODO: check if this is correct\n",
    "loss_weights = torch.tensor([neg_weight if x[0] == 1 else pos_weight for x in batch['label']])\n",
    "loss_weights = torch.tensor([neg_weight, pos_weight]).to(device) # or this\n",
    "model_v = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "\n",
    "# Classical training loop:\n",
    "import pickle\n",
    "loss_log = []\n",
    "epoch0 = 0\n",
    "if os.path.exists(\"model/temp.state\"):\n",
    "    with open(\"model/temp.state\", \"rb\") as f:\n",
    "        state = pickle.load(f)\n",
    "        loss_log = state['loss_log']\n",
    "        epoch0 = state['epoch']\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "model.train()\n",
    "batches = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "for epoch in range(epoch0, epochs):\n",
    "    for i, batch in enumerate(tqdm(batches)):\n",
    "        class_weights = torch.tensor([neg_weight if x[0] == 1 else pos_weight for x in batch['labels']]).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(batch, weights=class_weights)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_log.append(loss.cpu().detach().item())\n",
    "        if (i+1) % (len(batches) // 20) == 0:\n",
    "            print(np.mean(loss_log[-5000:]))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
